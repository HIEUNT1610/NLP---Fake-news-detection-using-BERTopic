# NLP---Fake-news-detection-using-BERTopic
A simple demo on fake news detection using topic modelling.
            
This demo app is built to tackle the problem of fake news detection using topic modelling. The idea is that we can detect fake news by comparing the topic of a given document or a news article, and then compare it to the topics generated by the two BERTopic models using the two datasets. Suppose the topic of the input document is similar to the topics in the fake news dataset. In that case, the input document is likely to be in a common fake news topic and therefore is likely to warrant a further assessment of veracity. This is by no means a perfect solution to detect fake news, but it can be a good way to quickly skim through a large number of documents and articles to find the ones that are most likely to be fake. 

This demo app's purpose is to: (i) provide a quick detection tool for further analysis; (ii) demonstrate my ability in looking at a problem and creating a solution from end to end.
            
The backbone of the demo is BERTopic, a topic modeling technique that leverages BERT embeddings and c-TF-IDF to create dense clusters allowing for easily interpretable topics whilst keeping important words in the topic descriptions.
            
The models used in the demo were trained on the Misinfo dataset from Kaggle, based on EUvsDisinfo data, using miniLM Sentence Transformer embedding. This application seeks to combine unsupervised learning techniques and labelled data to detect fake news. Two BERTopic models were used to model topics based on the fake and true news datasets. Prediction is done by generating the input topic and comparing it to the topics clustered by the model based on the two datasets. If the input topic is similar to the topics in the fake news dataset, the input is detected to be possibly fake news and requires further fact-checking.                      
            
There currently are two versions: the smaller version for Streamlit gives reasonable results but could be improved due to the limited hosting space of Streamlit Community Cloud; the bigger version gives better and more easily interpreted topics, and it is showing promises. Better and larger embedding models (such as paraphrase-multilingual-mpnet-base-v2) can give much better detection. Performance can also be further improved upon by continually adding more data to the training set. Another deployment on the Google Cloud Service for the bigger version will be available soon.
